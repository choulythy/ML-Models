---
title: "Assignment 10: Clustering"
author: "Chouly Thy"
format: html
editor: source
  markdown: 
    wrap: 72
self-contained: true
toc: true
toc-expand: true
toc-depth: 3
---

```{r setup, include=FALSE}
rm(list = ls()) # clears global environment
knitr::opts_knit$set(root.dir = '/Users/choulythy/Downloads/QTM6300 Data')
```

# Context

You have salary and compensation data for a set of public employees in San Francisco in Employee_Compensation_SF.csv. This data set includes the following variables for salary in 2016:

Employee Identifier: Unique ID for each employee Organization: Organization within San Francisco's government Department: Department within Orgniaztion Union: Union abbreviation Job Family: Type of job Job: Job Title Salary: Annual Salary (in \$USD) Overtime: Overtime Salary (in \$USD) Other Salaries: Other Salary, which could include contractor salary, one-time bonuses, extra work taken on, etc. (in \$USD) Total Salary: Sum of three salary numbers (in \$USD) Retirement: Amount paid into retirement (in \$USD) Health/Dental: Amount paid into Health/Dental (in \$USD) Other Benefits: Other Benefits, such as dependent care, FSA, etc. (in \$USD) Total Compensation: Total Compensation, including salaries and benefits (in \$USD)

## Question 1

Do the following: \* Import the data. \* Remove all inappropriate variables for k-means clustering \* Remove any rows with missing values \* Standardize your remaining variables

```{r}
#import data
df <- read.csv("Employee_Compensation_SF.csv")

df$Employee.Identifier = NULL
df$Organization.Group = NULL 
df$Department = NULL 
df$Union = NULL 
df$Job.Family = NULL
df$Job = NULL


df <- na.omit(df) 

library(caret)
standardizer <- preProcess(df, c("center","scale")) 
df <- predict(standardizer, df)

```

## Question 2

Use ggplot to plot the relationship between Total Salary and Total Benefits. What is the relationship between the two variables?

Answer:

```{r}
#plot data
library(ggplot2)
ggplot(df,aes(x=Total.Salary,y=Total.Benefits)) +
  geom_point()


```

## Question 3

Now, we want to do k-means clustering. Before we do, create an Elbow Chart. What would you argue is the "best" number of k?

Answer:Between 4 to 7

```{r}
source('BabsonAnalytics.R')
elbowChart(df)
```

## Question 4

Now, run a k-means clustering. Use 4 as the number of clusters. Given the size of the data set, feel free to use nstart = 10, as this will lower computational time.

```{r}
set.seed(1234)
model <- kmeans(df, centers=4, nstart=10) 

```

## Question 5

Take a look at the cluster size and centers. How would you describe each of your clusters? What seems to distinguish each cluster from the others? Also, which cluster is the largest?

Answer:Cluster 1 represents individuals with high salaries and benefits with strong total compensation, retirement, and additional benefits. Cluster 2 includes those with low salary and benefits across all categories, indicating a less favorable compensation package. Cluster 3 includes a balanced salary and benefits, with moderate values for salary, health, dental, and other benefits. Cluster 4 is distinguished by high overtime and additional salary components, along with a strong total compensation, but lower other benefits. Cluster 1 appears to be the largest, given its strong positive values in salary and benefits.

```{r}
model$size
model$centers
```

## Question 6

Bind the clusters with the data frame. Use this new data frame to create a plot with Total Salary and Total Benefits. Make sure each cluster is a different color on your graph.

```{r}
clusters <- cbind(df, cluster = model$cluster)

ggplot(df,aes(x=Total.Salary,y=Total.Benefits,col=model$cluster)) +
  geom_point()
```

## Question 7

Now, let's run hierarchichal clustering. Do the following: \* Import the raw data into R again. \* Keep only three columns: Employee Identifier, Total Salary, and Total Benefits. \* Standardize your variables.

```{r}
rm(list = ls()) # clears global environment
#import data
df <- read.csv("Employee_Compensation_SF.csv")

df <- df[,c("Employee.Identifier","Total.Salary","Total.Benefits")]

#Standardize Variables
library(caret)
standardizer <- preProcess(df,method = c("scale","center"))
df <- predict(standardizer, df)
```

## Question 8

Try to obtain the distance matrix. What happens?

Answer: There's an error of vector memory limit reached

```{r}
#d <- dist(df) 
#d
```

## Question 9

Now keep only the first 200 rows of data with the three variables mentioned in Question 7. Obtain the distance matrix. Then Model with average linkage, single linkage, and complete linkage and plot the dendrograms. Notice that the dendrogram plots are not useful. What is the issue with the data that makes heirarchical clustering not useful?

Answer: It is hard see where the clusters each employee is in.

```{r}
df <- df[1:200,c("Employee.Identifier","Total.Salary","Total.Benefits")]

d <- dist(df) 
d
```
