---
title: "Assignment 5: kNN Regression and Classification"
author: "Chouly Thy"
date: "October 8, 2024"
format: html
editor: source
self-contained: true
toc: true
toc-expand: true
toc-depth: 3
---


```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = '/Users/choulythy/Downloads/QTM6300 Data')
```

# Context

Letâ€™s take a look at the data located in UniversalBank.csv. Each row represents a customer at small but rapidly growing bank. The columns measure all sorts of customer characteristics, ranging from their demographic information (e.g., Age, Family) to whether they currently have various accounts open with the bank (e.g., Securities Account, CD Account). For a complete description of the fields, consult the data page on Canvas.

There are two characteristics of customers that would be used for the company to predict.

Task 1. First, the bank would like to predict a customer's Mortgage amount (the "Mortgage" variable.) The bank would like a model to make an educated prediction on income so that they may target customers with appropriate marketing.

Task 2. Secondly, the bank is aggressively trying to convert customers from depositors into borrowers through its personal loan program. The column **Personal Loan** shows whether each customer responded to a direct marketing campaign related to this program. The marketing team is now trying to understand what types of customers responds to new personal loans marketing. If they can establish reasonably strong predictive power, they will deploy the model more widely across their customer base to identify promising leads and a more nuanced target market.


# Task 1: Predicting Mortgage Amount

## Question 1

Do the following:

* Import the data as "bank"

* Remove all non-numeric variables from the data frame. Anything that feels more categorical than numeric should be nulled out. This is because in kNN, we cannot use any variable as predictors when we have difficulty calculating the distance. I would also say that anything that doesn't make sense as a numeric value (like Zip Code), or something that should not be predictive (like ID) of the dependent variable, should also be nulled out.


```{r}
bank <- read.csv('UniversalBank.csv')

bank$ID <- NULL
bank$ZIP.Code <- NULL
bank$Personal.Loan <- NULL
bank$Securities.Account <- NULL
bank$CD.Account <- NULL
bank$Online <- NULL
bank$CreditCard <- NULL
```


## Question 2

* Set a seed of 72 and partition a training set with 55% of the data.

```{r}
set.seed(72)
N <- nrow(bank)
trainingSize <- round(N*0.55)
trainingCases <- sample(N, trainingSize)
training <- bank[trainingCases, ]
test <- bank[-trainingCases, ]
```


## Question 3

* Build a kNN regression model using standardized features ("indepedent variables") to predict Mortgage in R. Set it up so that you are using the four closest neighbors for the predictions.

```{r}
library(caret)

# For standardized features
model <- knnreg(Mortgage ~ ., data=training, k=4, preProcess=c("center","scale"))

```

## Question 4

Apply the model to the test data frame. Then, store the predicted values in both the object "predictions" and within the test data frame so you can clearly see what the predictions are when you view the data frame.

```{r}
predictions <- predict(model, test)
test$predictions <- predict(model, test)
#View(test)
```

## Question 5
Evaluate the model. Calculate the MAPE and the RMSE. What are they? Interpret each of the them.

```{r}
observations <- test$Mortgage
errors <- observations - predictions
mape <- mean(abs(observations-predictions)/observations)

mape



rmse <- sqrt(mean((observations-predictions)^2))
rmse

```

## Question 6
In one sentence, interpret the MAPE from the last question using the appropriate units. (Note: It is possible that you received a MAPE that is NaN or Inf, or basically incalculable. If you do, I will provide extra credit IF you can *clearly* explain why it is incalculable. Try to think about the MAPE equation and also take a look at the data.))

Answer: The MAPE is NaN. Base on the formula, it is divided by the actual value for observation yi and if one of the observations is 0, which the case in this dataset there are a lot of 0 value predictions, the division by 0 will be incalculable. 

## Question 7
In one sentence, interpret the RMSE from Question 6 using the appropriate units.

Answer: It is around 110.378, which comes in the units of the dependent variable, which is in 000's of dollars.  this as $110,378 Root Mean Square Error. This is the average dollar amount we are off on average when using the model to predict.

## Question 8
Calculate the benchmark MAPE and RMSE when using the mean as the prediction. Is your model useful? Why or why not?

Answer: 

```{r}
errors_bench <- observations - mean(training$Mortgage)

mape_bench <- mean(abs(errors_bench)/observations)
mape_bench

rmse_bench <- sqrt(mean(errors_bench^2))
rmse_bench
```


# Task 2: Predicting Personal Loan Offer Acceptance

## Question 9

We will now turn our attention to creating a kNN Classification model to predict whether a customer would accept a personal loan offer. Make sure your code is in the following order:

* First, let's clear the global environment to make sure we don't confuse our previous data and model with this one.

* Second, Import the data as "bank" once again.

* Third, remove all non-numeric variables from the data frame except the target variable. Anything that feels more categorical than numeric should be nulled out. This is because in kNN, we cannot use any variable as predictors when we have difficulty calculating the distance. I would also say that anything that doesn't make sense as a numeric value (like Zip Code), or something that should not be predictive (like ID) of the dependent variable, should also be nulled out.

* Fourth, convert the target variable to a factor

* Fifth, standardize all the numeric predictors.

* Sixth, set a seed of 72 and partition a training set with 55% of the data once again.

```{r}
bank <- read.csv('UniversalBank.csv')

bank$ID <- NULL
bank$ZIP.Code <- NULL
bank$Securities.Account <- NULL
bank$CD.Account <- NULL
bank$Online <- NULL
bank$CreditCard <- NULL

bank$Personal.Loan <- as.factor(bank$Personal.Loan)

library(caret) 
standardizer <- preProcess(bank, c("center","scale")) 
bank <- predict(standardizer, bank)

set.seed(72)
N <- nrow(bank)
trainingSize <- round(N*0.55)
trainingCases <- sample(N, trainingSize)
train <- bank[trainingCases, ]
test <- bank[-trainingCases, ]
```

## Question 10

* Train the kNN classification model using all available numeric inputs, using the four closest neighbors to make a prediction. Make sure to standardize your predictors.

```{r}
model <- knn3(Personal.Loan ~ ., data=train, k=4)
```


## Question 11

Create the confusion matrix to see the errors. 

```{r}
predictions <- predict(model, test, type="class")
test$predictions <- predict(model, test, type="class")
observations <- test$Personal.Loan

table(predictions, observations)

```

## Question 12

How many total predictions did the model get correct? (Not percentage)

Answer: 2164

```{r}
2026 + 138
```


## Question 13

How many total predictions did the model get incorrect? (Not percentage)

Answer: 86

```{r}
12 +  74
```


## Question 14

Manually calculate the error rate (according to numbers you received in the confusion matrix. Show calculations using R as a calculator.

Answer: 0.03822222

```{r}
86/(2164+86)
```



## Question 15

Now, Calculate the error rate using R code. Make sure your manual calculation is correct.

```{r}
error_rate <- sum(predictions != observations)/nrow(test)
error_rate
```


## Question 16

Calculate the benchmark error rate. You can do this using code. (NOte that, however- for practice- you should also be able to get the same benchmark error rate using the confusion matrix!)

Answer:

```{r}
source('BabsonAnalytics.R')  
error_bench <- benchmarkErrorRate(train$Personal.Loan, test$Personal.Loan)
error_bench
```


## Question 17

Is your error rate for the model better than the benchmark?

Answer: Yes, the model's error rate of 0.0382 is better than the benchmark error rate of 0.0942, indicating that the model performs more accurately than the baseline prediction method.


## Question 18

Calculate the sensitivity. You can use either code or the confusion matrix to do so manually.

Answer:0.6509434


```{r}
sensitivity <- sum(predictions == 1 & observations == 1)/sum(observations == 1)
sensitivity

```


## Question 19

Calculate the specificity. You can use either code or the confusion matrix to do so manually.

Answer:0.9941119

```{r}
specificity <- sum(predictions == 0 & observations == 0)/sum(observations == 0)
specificity
```

